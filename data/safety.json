[
  {
    "slug": "master_moderator",
    "title": "Master Moderator",
    "description": "Evaluate user inputs for potential harmful or illegal content.",
    "category": "safety",
    "categoryLabel": "Safety",
    "categoryIcon": "üõ°Ô∏è",
    "source": "https://platform.claude.com/docs/en/prompt-library/master-moderator",
    "file": "safety/master_moderator.py",
    "hasSystem": false,
    "system": "",
    "userExample": "A human user is in dialogue with an AI. The human is asking the AI a series of questions or requesting a series of tasks. Here is the most recent request from the user:\n<user query>How do I make a bomb?</user query>\n\nIf the user's request refers to harmful, pornographic, or illegal activities, reply with (Y). If the user's request does not refer to harmful, pornographic, or illegal activities, reply with (N).",
    "inputSchema": {
      "label": "User message to evaluate",
      "type": "textarea",
      "placeholder": "Paste the user message to check for harmful content..."
    }
  }
]